{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning CNN model to recognize face\n",
    "'''This script uses a database of images and creates CNN model on top of it to test\n",
    "   if the given image is recognized correctly or not'''\n",
    "\n",
    "'''####### IMAGE PRE-PROCESSING for TRAINING and TESTING data #######'''\n",
    "\n",
    "# Specifying the folder where images are present\n",
    "TrainingImagePath='F:\\secure_locker\\Training_sets'\n",
    "TestingImagePath='F:\\secure_locker\\Testing_sets'\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Understand more about ImageDataGenerator at below link\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "# Defining pre-processing transformations on raw images of training data\n",
    "# These hyper parameters helps to generate slightly twisted versions\n",
    "# of the original image, which leads to a better model, since it learns\n",
    "# on the good and bad mix of images\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Defining pre-processing transformations on raw images of testing data\n",
    "# No transformations are done on the testing images\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Generating the Training Data\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=10,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "# Generating the Testing Data\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Printing class labels for each face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b28387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OutputNeurons = len(test_set.class_indices)\n",
    "OutputNeurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cf6ee22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chiran': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d4e4662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_14268\\3061074991.py:44: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.8790 - accuracy: 0.0000e+00WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "1/1 [==============================] - 14s 14s/step - loss: 16.8790 - accuracy: 0.0000e+00 - val_loss: 448.4999 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 450.7895 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 481.6525 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 469.4712 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 105.0494 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 155.0657 - accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 159.1070 - accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 95.9746 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 92.3230 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 371.5219 - accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 413.7101 - accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 702.3633 - accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 831.5977 - accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 677.6055 - accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 411.3484 - accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 347.1984 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 796.1562 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 807.7969 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 87.2312 - accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3209.2124 - accuracy: 0.0000e+00\n",
      "###### Total Time Taken:  1 Minutes ######\n"
     ]
    }
   ],
   "source": [
    "'''######################## Create CNN deep learning model ########################'''\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "'''Initializing the Convolutional Neural Network'''\n",
    "classifier= Sequential()\n",
    "\n",
    "''' STEP--1 Convolution\n",
    "# Adding the first layer of CNN\n",
    "# we are using the format (64,64,3) because we are using TensorFlow backend\n",
    "# It means 3 matrix of size (64X64) pixels representing Red, Green and Blue components of pixels\n",
    "'''\n",
    "classifier.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
    "\n",
    "'''# STEP--2 MAX Pooling'''\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "'''############## ADDITIONAL LAYER of CONVOLUTION for better accuracy #################'''\n",
    "classifier.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "'''# STEP--3 FLattening'''\n",
    "classifier.add(Flatten())\n",
    "\n",
    "'''# STEP--4 Fully Connected Neural Network'''\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "# classifier.add(Dense(2))\n",
    "classifier.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "'''# Compiling the CNN'''\n",
    "#classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "\n",
    "###########################################################\n",
    "import time\n",
    "# Measuring the time taken by the model to train\n",
    "StartTime=time.time()\n",
    "\n",
    "# Starting the model training\n",
    "classifier.fit_generator(\n",
    "                    training_set,\n",
    "                    steps_per_epoch=1,\n",
    "                    epochs=20,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=10)\n",
    "\n",
    "EndTime=time.time()\n",
    "print(\"###### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes ######')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "498bf168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "'''########### Making single predictions ###########'''\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "# import cv2\n",
    "# for i in range(5):\n",
    "ImagePath=f'F:/secure_locker/Testing_sets/Chiran/1.jpg'\n",
    "test_image=image.load_img(ImagePath,target_size=(64, 64))\n",
    "# test_img = cv2.resize(cv2.imread(ImagePath), (64, 64))\n",
    "test_image=image.img_to_array(test_image)\n",
    "\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "result=classifier.predict(test_image,verbose=0)\n",
    "#print(training_set.class_indices)\n",
    "\n",
    "print((result))\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87ae62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 1 classes.\n",
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'F:Training_sets',\n",
    "    target_size=(64, 64),  # Adjust the target size based on your model architecture\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Change to 'categorical' if you have more than two classes\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'F:Testing_sets',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01ee2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape=(64, 64, 3))  # Adjust input_shape based on your images\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9eac0c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.7064 - accuracy: 0.0000e+00 - val_loss: 0.1531 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2298 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 3.7670e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.7419e-04 - accuracy: 1.0000 - val_loss: 4.8767e-10 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.3028e-07 - accuracy: 1.0000 - val_loss: 1.0114e-14 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 6.0564e-10 - accuracy: 1.0000 - val_loss: 4.3380e-20 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4477e-13 - accuracy: 1.0000 - val_loss: 5.2418e-26 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.4928e-18 - accuracy: 1.0000 - val_loss: 2.4362e-32 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.8480e-21 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 3.1622e-26 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Adjust the number of epochs based on your dataset\n",
    "    validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70e11dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "print(f'Test Accuracy: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c60e88aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [50], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# evaluate the model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(validation_generator, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_884jrcd.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(train_generator, epochs=15, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(validation_generator, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
